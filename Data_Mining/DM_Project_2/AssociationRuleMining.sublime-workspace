{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"large",
				"largestK	statement"
			],
			[
				"count",
				"countOnK	statement"
			],
			[
				"larg",
				"largestK	statement"
			],
			[
				"pr",
				"print	function"
			],
			[
				"prod",
				"products	param"
			],
			[
				"s",
				"subset	forstmt"
			],
			[
				"Item",
				"itemSet	statement"
			],
			[
				"list",
				"listOfSubsets	statement"
			],
			[
				"foun",
				"found_set"
			],
			[
				"item",
				"itemSet	statement"
			],
			[
				"fre",
				"freqItemSet"
			],
			[
				"my",
				"myList	statement"
			],
			[
				"cond",
				"condifience"
			],
			[
				"set",
				"set_parent	statement"
			],
			[
				"suppo",
				"supportDict	statement"
			],
			[
				"it",
				"itemsetWithSupport	forstmt"
			],
			[
				"sup",
				"supportDict	statement"
			],
			[
				"tra",
				"transactions	param"
			],
			[
				"freli",
				"freqList_prelim"
			],
			[
				"tran",
				"transaction	forstmt"
			],
			[
				"trans",
				"transactions	statement"
			],
			[
				"pro",
				"products	statement"
			],
			[
				"produ",
				"product"
			],
			[
				"include",
				"include_support"
			],
			[
				"inclu",
				"include_support"
			],
			[
				"supp",
				"support_minThresh	statement"
			],
			[
				"bub",
				"bubble_sort"
			],
			[
				"freque",
				"frequentizeAndOrder	function"
			],
			[
				"transac",
				"transaction"
			],
			[
				"name",
				"namedtuple	function"
			],
			[
				"def",
				"defaultdict	class"
			],
			[
				"cre",
				"createNode	function"
			],
			[
				"val",
				"value	statement"
			],
			[
				"non",
				"None	keyword"
			],
			[
				"temp",
				"tempTransaction	statement"
			],
			[
				"T",
				"True	instance"
			],
			[
				"to",
				"toBeRemoved	statement"
			],
			[
				"inde",
				"index_inner	forstmt"
			],
			[
				"remo",
				"remove_values_from_list	function"
			],
			[
				"r",
				"remove	function"
			],
			[
				"ind",
				"index_inner	forstmt"
			],
			[
				"tr",
				"transactions"
			],
			[
				"li",
				"list_element	statement"
			],
			[
				"prun",
				"prune_onSupport"
			],
			[
				"ra",
				"range	function"
			],
			[
				"a",
				"append	function"
			],
			[
				"load_",
				"load_transactions	function"
			],
			[
				"nae",
				"name	statement"
			],
			[
				"load",
				"load_products	function"
			],
			[
				"line",
				"lineList	statement"
			],
			[
				"lin",
				"lineList"
			]
		]
	},
	"buffers":
	[
		{
			"contents": "from __future__ import print_function\nimport  collections\nfrom itertools import imap\nfrom collections import defaultdict, namedtuple\nimport itertools\n\ndef remove_values_from_list(the_list, val):\n   return [value for value in the_list if value != val]\n\n#  load from file functions\ndef load_products(filename_products, products):\n    f = open(filename_products, 'r')\n    for line in f:\n        lineList = line.split()\n        if lineList:\n            name = \"\"\n            for index in range(len(lineList)-1):\n                name += lineList[index]\n            products.append(name)\n    f.close()\n\ndef load_transactions(filename_transactions, transactions):\n    f = open(filename_transactions, 'r')\n    for line in f:\n        lineList = line.split()\n        transaction = []\n        for index in range(len(lineList)):\n            if index != 0: # ignore first element\n\n                if ( int(lineList[index][0]) != 0):\n                    transaction.append((index - 1))\n        transactions.append(transaction)\n    f.close()\n\n#  EXPLAIN THIS\ndef bubble_sort(items,freqList):\n    for i in range(len(items)):\n        for j in range(len(items)-1-i):\n            for element in freqList:\n                if items[j] == element[0]:\n                    freq0 = element[1]\n                if items[j+1] == element[0]:\n                    freq1 = element[1]\n            if freq0 < freq1:\n                items[j], items[j+1] = items[j+1], items[j]\n\n#  tree functions EXPLAIN THIS\nclass FPTree(object):\n\n    Route = namedtuple('Route', 'head tail')\n\n    def __init__(self):\n        # The root node of the tree.\n        self._root = FPNode(self, None, None)\n\n        # dictionary mapping items to the head and tail of a path of\n        # neighbors that will hit every node containing that item\n        self._routes = {}\n\n    @property\n    def root(self):\n        # root node of tree\n        return self._root\n\n    def add(self, transaction):\n       #  add transaction to tree\n        point = self._root\n\n        for item in transaction:\n            next_point = point.search(item)\n            if next_point:\n                # There is already a node in this tree for the current\n                # transaction item, then use it again\n                next_point.increment()\n            else:\n                # Create a new point and add it as a child of the point currently\n                # being looking at\n                next_point = FPNode(self, item)\n                point.add(next_point)\n\n                # Update the route of nodes that contain this item to include\n                # the new node\n                self._update_route(next_point)\n\n            point = next_point\n\n    def _update_route(self, point):\n        \"\"\"Add the given node to the route through all nodes for its item \"\"\"\n        assert self is point.tree\n\n        try:\n            route = self._routes[point.item]\n            route[1].neighbor = point # route[1] is the tail\n            self._routes[point.item] = self.Route(route[0], point)\n        except KeyError:\n            # First node for this item; start a new route.\n            self._routes[point.item] = self.Route(point, point)\n\n    def items(self):\n        \"\"\"\n        Generate one 2-tuples for each item represented in the tree. The first\n        element of the tuple is the item itself, and the second element is a\n        generator that will yield the nodes in the tree that belong to the item.\n        \"\"\"\n        for item in self._routes.iterkeys():\n            yield (item, self.nodes(item))\n\n    def nodes(self, item):\n        \"\"\"\n        Generate the sequence of nodes that contain the given item\n        \"\"\"\n\n        try:\n            node = self._routes[item][0]\n        except KeyError:\n            return\n\n        while node:\n            yield node\n            node = node.neighbor\n\n    def prefix_paths(self, item):\n        \"\"\"Generate  prefix paths that end with the given item\"\"\"\n\n        def collect_path(node):\n            path = []\n            while node and not node.root:\n                path.append(node)\n                node = node.parent\n            path.reverse()\n            return path\n\n        return (collect_path(node) for node in self.nodes(item))\n\n    def inspect(self):\n        print ('Tree:')\n        self.root.inspect(1)\n\n        print\n        print ('Routes:')\n        for item, nodes in self.items():\n            print ('  %r' % item)\n            for node in nodes:\n                print ('    %r' % node)\n\ndef cond_tree_from_paths(paths):\n    \"\"\"Build a conditional FP-tree from the given prefix paths.\"\"\"\n    tree = FPTree()\n    condition_item = None\n    items = set()\n\n    \"\"\"\"\n    # Import  nodes in the paths into the new tree... Nur die Zahlen von leaf nodes sind wichtig...\n     the remaining counts will be reconstructed from the eaf counts\n    \"\"\"\n    for path in paths:\n        if condition_item is None:\n            condition_item = path[-1].item\n\n        point = tree.root\n        for node in path:\n            next_point = point.search(node.item)\n            if not next_point:\n                # Add a new node to the tree.\n                items.add(node.item)\n                count = node.count if node.item == condition_item else 0\n                next_point = FPNode(tree, node.item, count)\n                point.add(next_point)\n                tree._update_route(next_point)\n            point = next_point\n\n    assert condition_item is not None\n\n    # Calc the counts of the non-leaf nodes\n    for path in tree.prefix_paths(condition_item):\n        count = path[-1].count\n        for node in reversed(path[:-1]):\n            node._count += count\n\n    return tree\n\nclass FPNode(object):\n\n    def __init__(self, tree, item, count=1):\n        self._tree = tree\n        self._item = item\n        self._count = count\n        self._parent = None\n        self._children = {}\n        self._neighbor = None\n\n    def add(self, child):\n        # add node as childe of this node\n\n        self._children[child.item] = child\n        child.parent = self\n\n    def search(self, item):\n\n        # if this node contains a child node for the given item, that node is returned... else `None` is returned\n\n        try:\n            return self._children[item]\n        except KeyError:\n            return None\n\n    def __contains__(self, item):\n        return item in self._children\n\n    @property\n    def tree(self):\n        return self._tree\n\n    @property\n    def item(self):\n        return self._item\n\n    @property\n    def count(self):\n        return self._count\n\n    def increment(self):\n        self._count += 1\n\n    @property\n    def root(self):\n        return self._item is None and self._count is None\n\n    @property\n    def leaf(self):\n        return len(self._children) == 0\n\n    @property\n    def parent(self):\n        return self._parent\n\n    @parent.setter\n    def parent(self, value):\n        self._parent = value\n\n    @property\n    def neighbor(self):\n        \"\"\"\n        The node's neighbor... the one with the same value that is \"to the right\"\n        of it in the tree\n        \"\"\"\n        return self._neighbor\n\n    @neighbor.setter\n    def neighbor(self, value):\n        self._neighbor = value\n\n    @property\n    def children(self):\n        return tuple(self._children.itervalues())\n\n    # def inspect(self, depth=0):\n    #     print ('  ' * depth) + repr(self)\n    #     for child in self.children:\n    #         child.inspect(depth + 1)\n\n    # def __repr__(self):\n    #     if self.root:\n    #         return \"<%s (root)>\" % type(self).__name__\n    #     return \"<%s %r (%r)>\" % (type(self).__name__, self.item, self.count)\n\n\n# EXPLAIN THIS:\n#  removes unfrequent products from transactions, then, for each transaction, order its freqeuent items according to the order in freqList.\ndef frequentizeAndOrder(transactions, freq_Thresh):\n    coll = collections.Counter(x for xs in transactions for x in set(xs))\n    total = float(sum(coll.values()))\n    freqList_prelim = [x for x in coll.most_common()]\n    freqList = []\n    list_element = []\n    transactions_adjusted = []\n    toBeRemoved = []\n\n    # print(freqList)\n\n    for i in range(len(freqList_prelim)):\n        list_element = []\n\n        if (freqList_prelim[i][1] / total > freq_Thresh):\n            list_element.append(freqList_prelim[i][0])\n            list_element.append(freqList_prelim[i][1])\n            freqList.append(list_element)\n        else:\n            #  go through entire list, remove all occurances of this value that is below support_thresh\n            toBeRemoved.append(freqList_prelim[i][0])\n\n        #  construct new list of lists with only frequent values\n    for transaction in transactions:\n        tempTransaction = []\n        for element in transaction:\n            valOK = True\n            for item in toBeRemoved:\n                if item == element:\n                    valOK = False\n            if valOK:\n                tempTransaction.append(element)\n\n        transactions_adjusted.append(tempTransaction)\n\n#  Now, for each transaction, order its freqeuent items according to the order in freqList.\n\n    for transaction in transactions_adjusted:\n        bubble_sort(transaction,freqList)\n\n    print(\"went from \", len(freqList_prelim), \"products to \", len(freqList))\n\n    return transactions_adjusted\n\ndef combinations(stuff):\n    myList = []\n    for L in range(1, len(stuff)):\n        for subset in itertools.combinations(stuff, L):\n            listy = []\n            for element in subset:\n                listy.append(element)\n            myList.append(listy)\n    return myList\n\n\ndef generateRules(transactions,products,minimum_support,minimum_confidence):\n    master = FPTree()\n\n    for transaction in transactions:\n        master.add(transaction)\n\n    total = float(len(transactions))\n\n    print (\"total # of transactions is: \", total)\n\n    supportDict = {}\n\n    def createSupportDict(tree, suffix ):\n        for item, nodes in tree.items():\n            supportCount = sum(n.count for n in nodes)\n            support = supportCount / total\n            found_set = [item] + suffix\n            yield (found_set, support)\n\n            if support >= minimum_support and item not in suffix:\n                cond_tree = cond_tree_from_paths(tree.prefix_paths(item))\n                for s in createSupportDict(cond_tree, found_set):\n                    yield s\n\n    #  make support dict for all sets\n    for itemsetWithSupport in createSupportDict(master, []):\n        supportDict[tuple(itemsetWithSupport[0])] = itemsetWithSupport[1]\n\n    def find_with_suffix(tree, suffix):\n\n        for item, nodes in tree.items():\n            supportCount = sum(n.count for n in nodes)\n            support = supportCount / total\n\n            if support >= minimum_support and item not in suffix:\n\n                found_set = [item] + suffix\n                set_parent = [item]\n\n                yield (found_set, support)\n\n                # build a conditional tree and recursively search for frequent\n                # itemsets within it\n                cond_tree = cond_tree_from_paths(tree.prefix_paths(item))\n                for s in find_with_suffix(cond_tree, found_set):\n                    yield s\n\n    # search for frequent itemsets, yield found results\n    freqItemSet = []\n    myList = []\n\n    for itemset in find_with_suffix(master, []):\n        freqItemSet.append(itemset)\n\n    for x in freqItemSet:\n        subList = []\n        # print(x)\n        subList = x\n        if len(subList[0]) > 1: # EXPLAIN THIS\n            myList.append(subList)\n\n    # print(\"mylist0: \", myList[0])\n    # myList = sorted(myList, key=lambda x: x[1], reverse=True)\n\n    largestK = 0;\n\n    for item in myList:\n        count = len(item[0])\n        # for product in item[0]:\n        #     print(products[product], end = \" \")\n        # print()\n\n        if count > largestK:\n            largestK = count\n\n        # print(item[1], \"K= \", count)\n\n    #  find largest K\n    countOnK = [0] * largestK # create list to count frequency of itemsets by K\n    for item in myList:\n        countOnK[ len(item[0]) - 1] = (countOnK[ len(item[0]) - 1] + 1)\n\n    # Number of frequent item sets (re port foreach K)\n    for kVal in range(len(countOnK) ):\n        if not (kVal == 0):\n            print(\"Number of frequent item sets with K =\", (kVal + 1), \"is\", countOnK[kVal])\n    # print(\"Number of frequent item sets with K =\", largestK, \"is\", countOnK[largestK])\n\n    print(\"Largest K is:\", largestK)\n\n    rules = []\n\n    for item in myList:\n        itemSet = item[0]\n        listOfSubsets = combinations(itemSet)\n        # print(listOfSubsets)\n        # print(itemSet)\n        for subset in listOfSubsets:         # for each subest c of i:\n            # print(subset, \",\", end = \" \")\n\n            itemSetMinusSubSet = []\n\n            for i in itemSet[:]: # remove common elements from itemSet that are in subSet\n                if i not in subset:\n                    itemSetMinusSubSet.append(i)\n\n            confidence = supportDict[tuple(itemSet)] / supportDict[tuple(itemSetMinusSubSet)]\n            if (confidence >= minimum_confidence):\n\n                rule = [ itemSetMinusSubSet, subset, supportDict[tuple(subset)], confidence  ]\n                rules.append(rule)\n                # print(rule)\n\n                # print(itemSetMinusSubSet, \"-->\", subset, \"confidence =\", confidence, \"and support =\", supportDict[tuple(subset)] ) # print\n    rules = sorted(rules, key=lambda x: x[2], reverse=True)\n\n    print(\"Number of rules generated is:\", (len(rules)))\n\n    for rule in rules:\n        for item in rule[0]:\n            print(products[item], end = \" \")\n\n        print(\"-->\", end = \" \")\n        for item in rule[1]:\n            print(products[item], end = \" \")\n        print(\"support = \", rule[2], \"and confidence =\", rule[3])\n\n#  main\ndef main():\n\n    #  DEFINE TRANSACTION AND PRODUTS FILES HERE\n    transactions_file = \"/Users/Konrad/Desktop/ar_test_data/small_basket.dat\"\n    products_file = \"/Users/Konrad/Desktop/ar_test_data/products\"\n\n      #  SPECIFY MIN SUPPORT AND CONFIDENCE HERE\n    support_min = .15 # to remove item sets based on support\n    confidence_min = 0.75 # to remove item sets based on confidence\n\n    freq_minThresh = .002 # to remove non-frequent products\n\n    products = list()\n    transactions_prelim = []\n    load_products(products_file, products)\n    load_transactions(transactions_file , transactions_prelim)\n\n    transactions = frequentizeAndOrder(transactions_prelim, freq_minThresh)\n\n    generateRules(transactions, products, support_min,confidence_min)\n\n\nif __name__ == \"__main__\":\n    main()\n\n",
			"file": "main.py",
			"file_size": 14556,
			"file_write_time": 131038364990000000,
			"settings":
			{
				"buffer_size": 14560,
				"line_ending": "Unix"
			}
		},
		{
			"contents": "\"\"\"\nA Python implementation of the FP-growth algorithm.\nBasic usage of the module is very simple:\n    > from fp_growth import find_frequent_itemsets\n    > find_frequent_itemsets(transactions, minimum_support)\n\"\"\"\n\nfrom collections import defaultdict, namedtuple\nfrom itertools import imap\n\ndef find_frequent_itemsets(transactions, minimum_support, include_support=False):\n    \"\"\"\n    Find frequent itemsets in the given transactions using FP-growth. This\n    function returns a generator instead of an eagerly-populated list of items.\n    The `transactions` parameter can be any iterable of iterables of items.\n    `minimum_support` should be an integer specifying the minimum number of\n    occurrences of an itemset for it to be accepted.\n    Each item must be hashable (i.e., it must be valid as a member of a\n    dictionary or a set).\n    If `include_support` is true, yield (itemset, support) pairs instead of\n    just the itemsets.\n    \"\"\"\n    items = defaultdict(lambda: 0) # mapping from items to their supports\n\n    # Load the passed-in transactions and count the support that individual\n    # items have.\n    for transaction in transactions:\n        for item in transaction:\n            items[item] += 1\n\n    # Remove infrequent items from the item support dictionary.\n    items = dict((item, support) for item, support in items.iteritems()\n        if support >= minimum_support)\n\n    # Build our FP-tree. Before any transactions can be added to the tree, they\n    # must be stripped of infrequent items and their surviving items must be\n    # sorted in decreasing order of frequency.\n    def clean_transaction(transaction):\n        transaction = filter(lambda v: v in items, transaction)\n        transaction.sort(key=lambda v: items[v], reverse=True)\n        return transaction\n\n    master = FPTree()\n    for transaction in imap(clean_transaction, transactions):\n        master.add(transaction)\n\n    def find_with_suffix(tree, suffix):\n        for item, nodes in tree.items():\n            support = sum(n.count for n in nodes)\n            if support >= minimum_support and item not in suffix:\n                # New winner!\n                found_set = [item] + suffix\n                yield (found_set, support) if include_support else found_set\n\n                # Build a conditional tree and recursively search for frequent\n                # itemsets within it.\n                cond_tree = conditional_tree_from_paths(tree.prefix_paths(item))\n                for s in find_with_suffix(cond_tree, found_set):\n                    yield s # pass along the good news to our caller\n\n    # Search for frequent itemsets, and yield the results we find.\n    for itemset in find_with_suffix(master, []):\n        yield itemset\n\nclass FPTree(object):\n    \"\"\"\n    An FP tree.\n    This object may only store transaction items that are hashable\n    (i.e., all items must be valid as dictionary keys or set members).\n    \"\"\"\n\n    Route = namedtuple('Route', 'head tail')\n\n    def __init__(self):\n        # The root node of the tree.\n        self._root = FPNode(self, None, None)\n\n        # A dictionary mapping items to the head and tail of a path of\n        # \"neighbors\" that will hit every node containing that item.\n        self._routes = {}\n\n    @property\n    def root(self):\n        \"\"\"The root node of the tree.\"\"\"\n        return self._root\n\n    def add(self, transaction):\n        \"\"\"Add a transaction to the tree.\"\"\"\n        point = self._root\n\n        for item in transaction:\n            next_point = point.search(item)\n            if next_point:\n                # There is already a node in this tree for the current\n                # transaction item; reuse it.\n                next_point.increment()\n            else:\n                # Create a new point and add it as a child of the point we're\n                # currently looking at.\n                next_point = FPNode(self, item)\n                point.add(next_point)\n\n                # Update the route of nodes that contain this item to include\n                # our new node.\n                self._update_route(next_point)\n\n            point = next_point\n\n    def _update_route(self, point):\n        \"\"\"Add the given node to the route through all nodes for its item.\"\"\"\n        assert self is point.tree\n\n        try:\n            route = self._routes[point.item]\n            route[1].neighbor = point # route[1] is the tail\n            self._routes[point.item] = self.Route(route[0], point)\n        except KeyError:\n            # First node for this item; start a new route.\n            self._routes[point.item] = self.Route(point, point)\n\n    def items(self):\n        \"\"\"\n        Generate one 2-tuples for each item represented in the tree. The first\n        element of the tuple is the item itself, and the second element is a\n        generator that will yield the nodes in the tree that belong to the item.\n        \"\"\"\n        for item in self._routes.iterkeys():\n            yield (item, self.nodes(item))\n\n    def nodes(self, item):\n        \"\"\"\n        Generate the sequence of nodes that contain the given item.\n        \"\"\"\n\n        try:\n            node = self._routes[item][0]\n        except KeyError:\n            return\n\n        while node:\n            yield node\n            node = node.neighbor\n\n    def prefix_paths(self, item):\n        \"\"\"Generate the prefix paths that end with the given item.\"\"\"\n\n        def collect_path(node):\n            path = []\n            while node and not node.root:\n                path.append(node)\n                node = node.parent\n            path.reverse()\n            return path\n\n        return (collect_path(node) for node in self.nodes(item))\n\n    def inspect(self):\n        print 'Tree:'\n        self.root.inspect(1)\n\n        print\n        print 'Routes:'\n        for item, nodes in self.items():\n            print '  %r' % item\n            for node in nodes:\n                print '    %r' % node\n\ndef conditional_tree_from_paths(paths):\n    \"\"\"Build a conditional FP-tree from the given prefix paths.\"\"\"\n    tree = FPTree()\n    condition_item = None\n    items = set()\n\n    # Import the nodes in the paths into the new tree. Only the counts of the\n    # leaf notes matter; the remaining counts will be reconstructed from the\n    # leaf counts.\n    for path in paths:\n        if condition_item is None:\n            condition_item = path[-1].item\n\n        point = tree.root\n        for node in path:\n            next_point = point.search(node.item)\n            if not next_point:\n                # Add a new node to the tree.\n                items.add(node.item)\n                count = node.count if node.item == condition_item else 0\n                next_point = FPNode(tree, node.item, count)\n                point.add(next_point)\n                tree._update_route(next_point)\n            point = next_point\n\n    assert condition_item is not None\n\n    # Calculate the counts of the non-leaf nodes.\n    for path in tree.prefix_paths(condition_item):\n        count = path[-1].count\n        for node in reversed(path[:-1]):\n            node._count += count\n\n    return tree\n\nclass FPNode(object):\n    \"\"\"A node in an FP tree.\"\"\"\n\n    def __init__(self, tree, item, count=1):\n        self._tree = tree\n        self._item = item\n        self._count = count\n        self._parent = None\n        self._children = {}\n        self._neighbor = None\n\n    def add(self, child):\n        \"\"\"Add the given FPNode `child` as a child of this node.\"\"\"\n\n        if not isinstance(child, FPNode):\n            raise TypeError(\"Can only add other FPNodes as children\")\n\n        if not child.item in self._children:\n            self._children[child.item] = child\n            child.parent = self\n\n    def search(self, item):\n        \"\"\"\n        Check whether this node contains a child node for the given item.\n        If so, that node is returned; otherwise, `None` is returned.\n        \"\"\"\n        try:\n            return self._children[item]\n        except KeyError:\n            return None\n\n    def __contains__(self, item):\n        return item in self._children\n\n    @property\n    def tree(self):\n        \"\"\"The tree in which this node appears.\"\"\"\n        return self._tree\n\n    @property\n    def item(self):\n        \"\"\"The item contained in this node.\"\"\"\n        return self._item\n\n    @property\n    def count(self):\n        \"\"\"The count associated with this node's item.\"\"\"\n        return self._count\n\n    def increment(self):\n        \"\"\"Increment the count associated with this node's item.\"\"\"\n        if self._count is None:\n            raise ValueError(\"Root nodes have no associated count.\")\n        self._count += 1\n\n    @property\n    def root(self):\n        \"\"\"True if this node is the root of a tree; false if otherwise.\"\"\"\n        return self._item is None and self._count is None\n\n    @property\n    def leaf(self):\n        \"\"\"True if this node is a leaf in the tree; false if otherwise.\"\"\"\n        return len(self._children) == 0\n\n    @property\n    def parent(self):\n        \"\"\"The node's parent\"\"\"\n        return self._parent\n\n    @parent.setter\n    def parent(self, value):\n        if value is not None and not isinstance(value, FPNode):\n            raise TypeError(\"A node must have an FPNode as a parent.\")\n        if value and value.tree is not self.tree:\n            raise ValueError(\"Cannot have a parent from another tree.\")\n        self._parent = value\n\n    @property\n    def neighbor(self):\n        \"\"\"\n        The node's neighbor; the one with the same value that is \"to the right\"\n        of it in the tree.\n        \"\"\"\n        return self._neighbor\n\n    @neighbor.setter\n    def neighbor(self, value):\n        if value is not None and not isinstance(value, FPNode):\n            raise TypeError(\"A node must have an FPNode as a neighbor.\")\n        if value and value.tree is not self.tree:\n            raise ValueError(\"Cannot have a neighbor from another tree.\")\n        self._neighbor = value\n\n    @property\n    def children(self):\n        \"\"\"The nodes that are children of this node.\"\"\"\n        return tuple(self._children.itervalues())\n\n    def inspect(self, depth=0):\n        print ('  ' * depth) + repr(self)\n        for child in self.children:\n            child.inspect(depth + 1)\n\n    def __repr__(self):\n        if self.root:\n            return \"<%s (root)>\" % type(self).__name__\n        return \"<%s %r (%r)>\" % (type(self).__name__, self.item, self.count)\n\n\nif __name__ == '__main__':\n    from optparse import OptionParser\n    import csv\n\n    p = OptionParser(usage='%prog data_file')\n    p.add_option('-s', '--minimum-support', dest='minsup', type='int',\n        help='Minimum itemset support (default: 2)')\n    p.add_option('-n', '--numeric', dest='numeric', action='store_true',\n        help='Convert the values in datasets to numerals (default: false)')\n    p.set_defaults(minsup=2)\n    p.set_defaults(numeric=False)\n\n    options, args = p.parse_args()\n    if len(args) < 1:\n        p.error('must provide the path to a CSV file to read')\n\n    transactions = []\n    with open(args[0]) as database:\n        for row in csv.reader(database):\n            if options.numeric:\n                transaction = []\n                for item in row:\n                    transaction.append(long(item))\n                transactions.append(transaction)\n            else:\n                transactions.append(row)\n\n    result = []\n    for itemset, support in find_frequent_itemsets(transactions, options.minsup, True):\n        result.append((itemset,support))\n\n    result = sorted(result, key=lambda i: i[0])\n    for itemset, support in result:\n        print str(itemset) + ' ' + str(support)\n",
			"file": "myTest.py",
			"file_size": 11612,
			"file_write_time": 131024725090000000,
			"settings":
			{
				"buffer_size": 11612,
				"line_ending": "Unix"
			}
		},
		{
			"contents": "Package Control Messages\n========================\n\nMaterial Theme\n--------------\n\n  Material Theme for Sublime Text 3\n  https://github.com/equinusocio/material-theme\n  \n  ðŸ‘‰ Version 2.0.9 ðŸ‘ˆ\n  ********************************************************************************\n  \n  ðŸ® UI THEME\n  \n    âž¼ Removed Langs folder with extensions overwrite (This should fix the issue with the less syntax)\n",
			"settings":
			{
				"buffer_size": 393,
				"line_ending": "Unix",
				"name": "Package Control Messages",
				"read_only": true,
				"scratch": true
			}
		},
		{
			"file": "AssociationRuleMining.sublime-project",
			"settings":
			{
				"buffer_size": 247,
				"line_ending": "Unix"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 400.0,
		"last_filter": "pac",
		"selected_items":
		[
			[
				"pac",
				"Package Control: Install Package"
			],
			[
				"user",
				"Preferences: Package Control Settings â€“ User"
			],
			[
				"packages uese",
				"Preferences: Package Control Settings â€“ User"
			],
			[
				"pack",
				"Package Control: Install Package"
			],
			[
				"settings",
				"Preferences: Settings - User"
			],
			[
				"spacegr",
				"Preferences: Package Control Settings â€“ User"
			],
			[
				"setting",
				"Preferences: Package Control Settings â€“ User"
			],
			[
				"default",
				"Preferences: Settings - Default"
			],
			[
				"packe",
				"Package Control: Install Package"
			],
			[
				"install",
				"Package Control: Install Package"
			],
			[
				"get",
				"Package Control: Install Package"
			]
		],
		"width": 424.0
	},
	"console":
	{
		"height": 233.0,
		"history":
		[
			"import urllib.request,os,hashlib; h = '2915d1851351e5ee549c20394736b442' + '8bc59f460fa1548d1514676163dafc88'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)"
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/Users/Konrad/Desktop/DataMiningP2"
	],
	"file_history":
	[
		"/Users/Konrad/Desktop/DataMiningP2/test.py",
		"/Users/Konrad/Library/Application Support/Sublime Text 3/Packages/User/Anaconda.sublime-settings",
		"/Users/Konrad/Desktop/DataMiningP2/AssociationRuleMining.sublime-project",
		"/Users/Konrad/Library/Application Support/Sublime Text 3/Packages/User/Package Control.sublime-settings",
		"/Users/Konrad/Library/Application Support/Sublime Text 3/Packages/User/Preferences.sublime-settings",
		"/Users/Konrad/Library/Application Support/Sublime Text 3/Packages/Default/Preferences.sublime-settings"
	],
	"find":
	{
		"height": 38.0
	},
	"find_in_files":
	{
		"height": 0.0,
		"where_history":
		[
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"confidence",
			"confiden",
			"confdience",
			"include_support",
			"count",
			"print",
			"listy",
			"lisy",
			"products",
			"find_fre",
			"find",
			"prefix",
			"find_frequent_itemsets",
			"print",
			"sideb",
			"side"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "main.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 14560,
						"regions":
						{
						},
						"selection":
						[
							[
								14044,
								14044
							]
						],
						"settings":
						{
							"open_with_edit": true,
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "myTest.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 11612,
						"regions":
						{
						},
						"selection":
						[
							[
								289,
								289
							]
						],
						"settings":
						{
							"open_with_edit": true,
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 5279.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				}
			]
		},
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "main.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 14560,
						"regions":
						{
						},
						"selection":
						[
							[
								10748,
								10680
							]
						],
						"settings":
						{
							"open_with_edit": true,
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 241.0,
						"translation.y": 6068.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				},
				{
					"buffer": 2,
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 393,
						"regions":
						{
						},
						"selection":
						[
							[
								393,
								393
							]
						],
						"settings":
						{
							"auto_indent": false,
							"default_dir": "/Users/Konrad/Desktop/DataMiningP2",
							"syntax": "Packages/Text/Plain text.tmLanguage",
							"tab_width": 2,
							"word_wrap": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "AssociationRuleMining.sublime-project",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 247,
						"regions":
						{
						},
						"selection":
						[
							[
								200,
								204
							]
						],
						"settings":
						{
							"syntax": "Packages/JavaScript/JSON.sublime-syntax",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 26.0
	},
	"input":
	{
		"height": 38.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			],
			[
				1,
				0,
				2,
				1
			]
		],
		"cols":
		[
			0.0,
			0.94324631101,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.exec":
	{
		"height": 222.0
	},
	"output.find_results":
	{
		"height": 0.0
	},
	"pinned_build_system": "Anaconda Python Builder",
	"project": "AssociationRuleMining.sublime-project",
	"replace":
	{
		"height": 48.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 50.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
